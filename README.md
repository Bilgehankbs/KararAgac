# Makine Ã–ÄŸrenmesi Dersi 2 - Karar AÄŸacÄ±
Bu projede karar aÄŸacÄ± algoritmasÄ±nÄ± kullandÄ±m. Karar aÄŸacÄ±, makine Ã¶ÄŸrenmesinde Ã§ok popÃ¼ler bir algoritma. Veriyi her adÄ±mda ikiye bÃ¶lerek karar dÃ¼ÄŸÃ¼mleri oluÅŸturuyor. Her dÃ¼ÄŸÃ¼mde en iyi Ã¶zelliÄŸi seÃ§ip, o Ã¶zelliÄŸe gÃ¶re veriyi ayÄ±rÄ±yor. Bu sayede aÄŸaÃ§ yapÄ±sÄ±nda kararlar alarak tahmin yapÄ±yor. AlgoritmanÄ±n en gÃ¼zel yanÄ±, sonuÃ§larÄ± gÃ¶rsel olarak anlaÅŸÄ±lÄ±r ÅŸekilde sunmasÄ±. ÃœÃ§ farklÄ± problem Ã§Ã¶zdÃ¼m: Ä°ris sÄ±nÄ±flandÄ±rma, diabetes regresyon ve yapay veri seti.

## ğŸ¯ Ne YaptÄ±m?

Ä°ris Ã§iÃ§ek veri setini kullanarak 3 farklÄ± Ã§iÃ§ek tÃ¼rÃ¼nÃ¼ sÄ±nÄ±flandÄ±rmaya Ã§alÄ±ÅŸtÄ±m. Sonra diabetes veri setini kullanarak 10 Ã¶zellik ile diabetes ilerlemesini tahmin ettim. Son olarak sinÃ¼s fonksiyonu + gÃ¼rÃ¼ltÃ¼ oluÅŸturup iki farklÄ± max_depth deÄŸeri ile karÅŸÄ±laÅŸtÄ±rma yaptÄ±m. BunlarÄ± yaparken de Pandas, NumPy, Scikit-learn, Matplotlib Python kÃ¼tÃ¼phanelerini kullandÄ±m.

## ğŸ“ Kodda Neler YaptÄ±m?

Ä°ris sÄ±nÄ±flandÄ±rmada veri setini yÃ¼kledim, %80 eÄŸitim %20 test olarak bÃ¶ldÃ¼m. DecisionTreeClassifier ile model oluÅŸturdum. 
Diabetes regresyonda da aynÄ± ÅŸekilde %80 eÄŸitim %20 test bÃ¶ldÃ¼m, DecisionTreeRegressor ile model oluÅŸturdum. 
Yapay veri setinde ise sinÃ¼s fonksiyonu + gÃ¼rÃ¼ltÃ¼ oluÅŸturdum ve iki farklÄ± max_depth deÄŸeri ile karÅŸÄ±laÅŸtÄ±rma yaptÄ±m.

## SonuÃ§
Ä°ris sÄ±nÄ±flandÄ±rmada %100 doÄŸruluk aldÄ±m. En Ã¶nemli Ã¶zellik petal length Ã§Ä±ktÄ±. 
Diabetes regresyonda MSE: 4976.80, RMSE: 70.55 deÄŸerlerini elde ettim. 
Yapay veri setinde max depth=2 daha basit model, max depth=15 ise aÅŸÄ±rÄ± Ã¶ÄŸrenme riski taÅŸÄ±dÄ±ÄŸÄ±nÄ± gÃ¶rdÃ¼m.
Max_depth parametresi Ã§ok kritik olduÄŸunu Ã§ok bÃ¼yÃ¼kse aÅŸÄ±rÄ± Ã¶ÄŸrenme, Ã§ok kÃ¼Ã§Ã¼kse eksik Ã¶ÄŸrenmeye evrildiÄŸini gÃ¶zlemledim
Karar aÄŸacÄ± algoritmasÄ±nÄ±n en Ã¶nemli parametresi max_depth Ã§Ä±ktÄ±. Ã‡ok bÃ¼yÃ¼kse aÅŸÄ±rÄ± Ã¶ÄŸrenme, Ã§ok kÃ¼Ã§Ã¼kse eksik Ã¶ÄŸrenmeye yol aÃ§Ä±yor. KullandÄ±ÄŸÄ±m diÄŸer parametreler: criterion ("gini" veya "entropy"), max_depth, random_state.


## ğŸŒ³ Rasgele Orman Projesi

Bu projede rasgele orman algoritmasÄ±nÄ± kullandÄ±m. Rasgele orman, birden fazla karar aÄŸacÄ±nÄ±n bir araya gelmesiyle oluÅŸan gÃ¼Ã§lÃ¼ bir algoritma. Her aÄŸaÃ§ farklÄ± veri alt kÃ¼mesi Ã¼zerinde eÄŸitilip, sonunda oylama yaparak karar veriyor. Bu sayede tek karar aÄŸacÄ±ndan Ã§ok daha stabil ve doÄŸru sonuÃ§lar elde ediyor. Ä°ki farklÄ± problem Ã§Ã¶zdÃ¼m: yÃ¼z tanÄ±ma sÄ±nÄ±flandÄ±rmasÄ± ve ev fiyatÄ± tahmini.

### ğŸ¯ Ne YaptÄ±m?

Olivetti faces veri setini kullanarak yÃ¼z tanÄ±ma problemi Ã§Ã¶zdÃ¼m. Sonra California Housing veri seti ile ev fiyatÄ± tahmini yaptÄ±m. AÄŸaÃ§ sayÄ±sÄ±nÄ±n performansa etkisini de analiz ettim. Pandas, NumPy, Scikit-learn, Matplotlib kÃ¼tÃ¼phanelerini kullandÄ±m.

### ğŸ“ Kodda Neler YaptÄ±m?

YÃ¼z tanÄ±mada veri setini yÃ¼kledim, %80 eÄŸitim %20 test olarak bÃ¶ldÃ¼m. RandomForestClassifier ile model oluÅŸturdum. Ev fiyatÄ± tahmininde RandomForestRegressor kullandÄ±m. AÄŸaÃ§ sayÄ±sÄ±nÄ± 5'ten 250'ye kadar deÄŸiÅŸtirerek performans analizi yaptÄ±m. SonuÃ§ olarak yÃ¼z tanÄ±mada %93.75 doÄŸruluk elde ettim. AÄŸaÃ§ sayÄ±sÄ± arttÄ±kÃ§a performansÄ±n arttÄ±ÄŸÄ±nÄ± gÃ¶rdÃ¼m. Ev fiyatÄ± tahmininde ise RMSE: 0.505 deÄŸerini aldÄ±m. Rasgele orman algoritmasÄ±nÄ±n Ã§ok gÃ¼Ã§lÃ¼ olduÄŸunu, Ã¶zellikle aÄŸaÃ§ sayÄ±sÄ±nÄ±n artmasÄ±yla daha iyi sonuÃ§lar verdiÄŸini gÃ¶zlemledim.
